TRAINING_DATA_PATH="data/training"
SOURCE_DATA_PATH="data/evaluation/source" #TODO: add the EN source file name 
REFERENCE_DATA_PATH="data/evaluation/reference"
OUTPUT_DATA_PATH="data/evaluation/output"
METRIC_RESULTS_PATH="data/evaluation/metric_results"

MODEL_PATH="model/models"
ADAPTER_PATH="model/models/adapter"
COMET_PATH="model/models/comet/wmt20-comet-da/checkpoints/model.ckpt"
CTRANSLATE2_PATH="model/models/ctranslate2"
FINE_TUNED_PATH="model/models/fine_tuned"

MODEL_NAME="Meta-Llama-3.1-8B-Instruct"
HF_MODEL_NAME="meta-llama/Meta-Llama-3.1-8B-Instruct"

SOURCE_LANGUAGE = "English"
LANGUAGES = ['Brazilian Portugues','Czech','Finnish','German','Korean']
LANG_ABRV = ['pt-br','cs','fi','de','ko']

MAX_EPOCHS=10
BATCH_SIZE=64
LEARNING_RATE=1e-4

LENGTH_MULTIPLIER=2
TOPK=1

NUM_BEAMS=5

SAMPLE_NUMBER=42